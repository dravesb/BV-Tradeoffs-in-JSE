#       Two Dimensional MSE
#           Simulations
#
#--------------------------------------
#load packages and source files
library(pacman,lib.loc = "/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
p_load(MCMCpack, ggplot2, dplyr, reshape2)
setwd('/Users/benjamindraves/Documents/Work/github/BJSE/two_dim_BV_tradeoff/code/')
source('basic_functions.R')
source('model_setup_ER_to_SBM.R')
source('theoretical_mse_functions.R')
net_size <- c(250, 500, 750, 1000)
mc_runs <- 100
#set up storage
here <- 1
df <- matrix(NA, nrow = sum(net_size)*length(t)*mc_runs, ncol = 7)
colnames(df) <- c('iter_no','t','node_id', 'net_size', 'comm', 'X', 'Y')
#set pointers
count <- 0
#set seed
set.seed(1985)
for(n in 1:length(net_size)){
for(j in 1:length(t)){
#sample rows of X
comm_ids <- rep(1:2, each = net_size[n]/2)
Xc <- L[comm_ids,] %*% sqrt(C(t[j]))
P2 <- tcrossprod(Xc)
for(i in 1:mc_runs){
#update pointers
start <- ifelse(count == 0, 1, stop + 1)
stop <- start + net_size[n] - 1
count <- 1
#sampleA2
A2 <- sampP(P2)
#----------------------
#   ASE
#----------------------
#embedd individually
Y_hat.here <- ase(A2, 2)
#align matrices
Y_hat <- procrustes(Y_hat.here, Xc)$X.new
#store
df[start:stop, ] <- cbind(rep(i, net_size[n]), #iteration number
rep(t[j], net_size[n]), #t
1:net_size[n] , #node id
rep(net_size[n], net_size[n]), #net_size
comm_ids, #community ids
Y_hat#estimate
)
}
#print update
print(j/length(t))
}
}
#restructure dataframe
plotdf <- data.frame(iter_no = as.factor(df[,1]),
t = as.numeric(df[,2]),
node_id = as.factor(df[,3]),
net_size = as.factor(df[,4]),
comm = as.numeric(df[,5]),
estimate_X = as.numeric(df[,6]),
estimate_Y = as.numeric(df[,7])) %>%
group_by(node_id, t, comm, net_size) %>%
summarize(average_estimate_X = mean(estimate_X),
average_estimate_Y = mean(estimate_Y))
#theoretic lines
Lc <- function(j) L %*% sqrt(C(t[j]))
mat <- matrix(NA, ncol = 5, nrow = 4*length(t))
colnames(mat) <-  c('X', 'Y', 't', 'comm', 'graph')
for(j in 1:length(t)){
mat[(4*j-3):(4*j - 2),] <- cbind(Lc(j), c(t[j], t[j]), 1:2, rep('Graph 2', 2))
mat[(4*j-1):(4*j),] <- cbind(L, c(t[j], t[j]), 1:2, rep('Graph 1', 2))
}
mat_df <- as.data.frame(mat)
mat_df[,1] <- as.numeric(as.character(mat_df[,1]))
mat_df[,2] <- as.numeric(as.character(mat_df[,2]))
mat_df[,3] <- as.numeric(as.character(mat_df[,3]))
plotdf2 <- merge(plotdf, mat_df[,-5], by = c('comm', 't'), all.x = TRUE)
ggplot(plotdf2, aes(average_estimate_X, average_estimate_Y, col = t))+
geom_point(alpha = .5, size = .1)+
geom_line(aes(X, Y, group = comm))+
facet_grid(rows = vars(net_size))
ggsave(filename = "finite_bias.pdf",
width = 5, height = 8,
path = "/Users/benjamindraves/Documents/Work/github/DravesOmnibus/finite_bias_ase",
units = "in")
ggsave(filename = "finite_bias.jpeg",
width = 5, height = 8,
path = "/Users/benjamindraves/Documents/Work/github/DravesOmnibus/finite_bias_ase",
units = "in")
rm(list = ls)
rm(list = ls())
#load up necessary packages
library(ggplot2)
library(dplyr)
library(reshape2)
library(matlib)
#--------------------------------------
#
#       Multiple Graph Embedding
#         Clustering Simulation
#           4 Group
#--------------------------------------
#-----------------------------
#     Preliminaries
#-----------------------------
#load up necessary packages
library(ggplot2)
library(dplyr)
library(reshape2)
library(matlib)
library(irlba)
library(mclust)
#source nesseary functions
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/je_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/mase_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/omni_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/mrdpg_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/omnicat_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/model_setup_4_group.R")
#define storage
names <- c("network_size", "t","iter.no",
"Omnibar",'Omnicat', "MASE", "JE", "MRDPG",
'ASE1', 'ASE2', 'ASE3', 'ASE4')
df <- matrix(NA, ncol = length(names), nrow = length(t) * mc_runs * length(net_size))
colnames(df) <- names
here <- 1
#set seed
set.seed(1985)
library(ggplot2)
library(dplyr)
library(reshape2)
df <- as.data.frame(read.csv("~/Documents/Work/github/BJSE/multiple_network_methods/data/data_4_group.csv")[,-1])
#group by iteration & method
df <- df %>% melt(id.vars = 1:3) %>%
group_by(network_size, t, variable) %>%
summarize(MC_Rate = mean(value, na.rm = TRUE),
se_rate = sd(value, na.rm = TRUE)/sqrt(n())) %>%
mutate(Type = rep(c('Multiplex', 'Individual'), c(5, 4)))
colnames(df)[3] <- "Method"
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
#geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
i
i <- 25
t
l
l <- 1
net_size
mc_runs
j <- 1
#sample group assignments
samp <- sample(1:3, net_size[l], replace = TRUE)
X <- L[samp,]
#get different P matrices
P1 <- tcrossprod(X)
P2 <- X %*% tcrossprod(C1(t[i]), X)
P3 <- X %*% tcrossprod(C2(t[i]), X)
P4 <- X %*% tcrossprod(C3(t[i]), X)
L %*% tcrossprod(C2(t[i]), L)
C2
L %*% tcrossprod(C2(1), L)
L %*% tcrossprod(C2(1))
C2
C3
C1
C1
L %*% tcrossprod(C1(1), L)
L %*% tcrossprod(C1(t[25]), L)
L %*% tcrossprod(C2(t[25]), L)
L %*% tcrossprod(C3(t[25]), L)
L %*% tcrossprod(C1(1), L)
L %*% tcrossprod(C2(1), L)
L %*% tcrossprod(C3(1), L)
C3
C2
C1
i
P2 <- X %*% tcrossprod(C1(t[i]), X)
table(P2)
A2 <- sampP(P2)
#make adjaceny lists
adj_mats <- list()
adj_mats[[1]] <- A1
adj_mats[[2]] <- A2
adj_mats[[3]] <- A3
adj_mats[[4]] <- A4
#get classifications from each methods
invisible(capture.output(omni_estimates <- omni_classes(adj_mats, 3, 3)))
#sample group assignments
samp <- sample(1:3, net_size[l], replace = TRUE)
X <- L[samp,]
#get different P matrices
P1 <- tcrossprod(X)
P2 <- X %*% tcrossprod(C1(t[i]), X)
P3 <- X %*% tcrossprod(C2(t[i]), X)
P4 <- X %*% tcrossprod(C3(t[i]), X)
#sample adjaceny matrices
A1 <- sampP(P1)
A2 <- sampP(P2)
A3 <- sampP(P3)
A4 <- sampP(P4)
#make adjaceny lists
adj_mats <- list()
adj_mats[[1]] <- A1
adj_mats[[2]] <- A2
adj_mats[[3]] <- A3
adj_mats[[4]] <- A4
#get classifications from each methods
invisible(capture.output(omni_estimates <- omni_classes(adj_mats, 3, 3)))
invisible(capture.output(omnicat_estimates <- omnicat_classes(adj_mats, 3, 3)))
invisible(capture.output(mrdpg_estimates <- mrdpg_classes(adj_mats, 3, 3)))
invisible(capture.output(je_estimates <- je_classes(adj_mats, 3, 3)))
invisible(capture.output(mase_estimates <- mase_classes(adj_mats, 3, 3)))
#get classifications from individual ASEs
X1 <- ase(A1, 3); X2 <- ase(A2, 3)
X3 <- ase(A3, 3); X4 <- ase(A4, 3)
plot(X1[,1])
plot(X1[,1:2])
plot(X1[,1:2], col = samp)
plot(X1[,c(1,3)], col = samp)
plot(X1[,c(2,3)], col = samp)
plot(X1[,c(1,2)], col = samp)
plot(X2[,c(1,2)], col = samp)
plot(X2[,c(1,3)], col = samp)
X2
install.packages("scatterplot3d") # Install
library("scatterplot3d") # load
scatterplot3d(X1)
scatterplot3d(X1, col = samp)
scatterplot3d(X1, color = samp)
scatterplot3d(X1, color = samp, type = 'h')
scatterplot3d(X1, color = samp, box = FALSE)
scatterplot3d(X2, color = samp, box = FALSE)
scatterplot3d(X3, color = samp, box = FALSE)
scatterplot3d(X4, color = samp, box = FALSE)
get_mc3
library(car)
scatter3d(X4, color = samp, box = FALSE)
scatter3d(x = X1[,1], y = X1[,2], z = X1[,3], color = samp)
scatter3d(x = X1[,1], y = X1[,2], z = X1[,3], color = samp, surface = FALSE)
scatter3d(x = X1[,1], y = X1[,2], z = X1[,3], groups = samp, surface = FALSE)
scatter3d(x = X1[,1], y = X1[,2], z = X1[,3], groups = as.factor(samp), surface = FALSE)
scatter3d(x = X2[,1], y = X2[,2], z = X2[,3], groups = as.factor(samp), surface = FALSE)
scatter3d(x = X3[,1], y = X3[,2], z = X3[,3], groups = as.factor(samp), surface = FALSE)
scatter3d(x = X4[,1], y = X4[,2], z = X4[,3], groups = as.factor(samp), surface = FALSE)
L
L
X
X %*% tcrossprod(C1(t[i]), X)
L %*% tcrossprod(C1(t[i]), L)
table(samp)
L %*% tcrossprod(C1(1), L)
X2
invisible(capture.output(ase2_estimates <- Mclust(X2, G = 3, modelNames = "VVV")$classification))
ase2_estimates
samp
ase2_mc <- get_mc3(ase2_estimates, samp)
ase2_mc
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
df <- as.data.frame(read.csv("~/Documents/Work/github/BJSE/multiple_network_methods/data/data_4_group.csv")[,-1])
#group by iteration & method
df <- df %>% melt(id.vars = 1:3) %>%
group_by(network_size, t, variable) %>%
summarize(MC_Rate = mean(value, na.rm = TRUE),
se_rate = sd(value, na.rm = TRUE)) %>%
mutate(Type = rep(c('Multiplex', 'Individual'), c(5, 4)))
df <- as.data.frame(read.csv("~/Documents/Work/github/BJSE/multiple_network_methods/data/data_4_group.csv")[,-1])
#group by iteration & method
df <- df %>% melt(id.vars = 1:3) %>%
group_by(network_size, t, variable) %>%
summarize(MC_Rate = mean(value, na.rm = TRUE),
se_rate = sd(value, na.rm = TRUE)) %>%
mutate(Type = rep(c('Multiplex', 'Individual'), c(5, 4)))
head(df)
colnames(df)[3] <- "Method"
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
# geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
# geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df %>% filter(methpd == 'ASE2'),
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df %>% filter(method == 'ASE2'),
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
head(df)
ggplot(df %>% filter(Method == 'ASE2'),
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
scatter3d(x = X1[,1], y = X1[,2], z = X1[,3], groups = as.factor(samp), surface = FALSE)
tcrossprod(L)
X %*% tcrossprod(C1(1), X)
L %*% tcrossprod(C1(1), L)
L %*% tcrossprod(C1(t[25]), L)
t <- seq(0, 1, length.out = 25)
t
#--------------------------------------
#
#       Multiple Graph Embedding
#         Clustering Simulation
#           4 Group
#--------------------------------------
#-----------------------------
#     Preliminaries
#-----------------------------
#load up necessary packages
library(ggplot2)
library(dplyr)
library(reshape2)
library(matlib)
library(irlba)
library(mclust)
#source nesseary functions
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/je_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/mase_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/omni_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/mrdpg_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/omnicat_classification.R")
source("~/Documents/Work/github/BJSE/multiple_network_methods/code/model_setup_4_group.R")
#define storage
names <- c("network_size", "t","iter.no",
"Omnibar",'Omnicat', "MASE", "JE", "MRDPG",
'ASE1', 'ASE2', 'ASE3', 'ASE4')
df <- matrix(NA, ncol = length(names), nrow = length(t) * mc_runs * length(net_size))
colnames(df) <- names
here <- 1
#set seed
set.seed(1985)
#-----------------------------
#     Do simulation
#-----------------------------
for(l in 1:length(net_size)){#loop over n
for(i in 1:length(t)){#loop over t
for(j in 1:mc_runs){#monte carlo iterations
#sample group assignments
samp <- sample(1:3, net_size[l], replace = TRUE)
X <- L[samp,]
#get different P matrices
P1 <- tcrossprod(X)
P2 <- X %*% tcrossprod(C1(t[i]), X)
P3 <- X %*% tcrossprod(C2(t[i]), X)
P4 <- X %*% tcrossprod(C3(t[i]), X)
#sample adjaceny matrices
A1 <- sampP(P1)
A2 <- sampP(P2)
A3 <- sampP(P3)
A4 <- sampP(P4)
#make adjaceny lists
adj_mats <- list()
adj_mats[[1]] <- A1
adj_mats[[2]] <- A2
adj_mats[[3]] <- A3
adj_mats[[4]] <- A4
#get classifications from each methods
invisible(capture.output(omni_estimates <- omni_classes(adj_mats, 3, 3)))
invisible(capture.output(omnicat_estimates <- omnicat_classes(adj_mats, 3, 3)))
invisible(capture.output(mrdpg_estimates <- mrdpg_classes(adj_mats, 3, 3)))
invisible(capture.output(je_estimates <- je_classes(adj_mats, 3, 3)))
invisible(capture.output(mase_estimates <- mase_classes(adj_mats, 3, 3)))
#get classifications from individual ASEs
X1 <- ase(A1, 3); X2 <- ase(A2, 3)
X3 <- ase(A3, 3); X4 <- ase(A4, 3)
invisible(capture.output(ase1_estimates <- Mclust(X1, G = 3, modelNames = "VVV")$classification))
invisible(capture.output(ase2_estimates <- Mclust(X2, G = 3, modelNames = "VVV")$classification))
invisible(capture.output(ase3_estimates <- Mclust(X3, G = 3, modelNames = "VVV")$classification))
invisible(capture.output(ase4_estimates <- Mclust(X4, G = 3, modelNames = "VVV")$classification))
#get MC rates
omni_mc <- get_mc3(omni_estimates, samp)
omnicat_mc <- get_mc3(omnicat_estimates, samp)
mrdpg_mc <- get_mc3(mrdpg_estimates, samp)
je_mc <- get_mc3(je_estimates, samp)
mase_mc <- get_mc3(mase_estimates, samp)
ase1_mc <- get_mc3(ase1_estimates, samp)
ase2_mc <- get_mc3(ase2_estimates, samp)
ase3_mc <- get_mc3(ase3_estimates, samp)
ase4_mc <- get_mc3(ase4_estimates, samp)
#store data
df[here, ] <- c(net_size[l], t[i], j, omni_mc, omnicat_mc, mase_mc, je_mc, mrdpg_mc,
ase1_mc, ase2_mc, ase3_mc,ase4_mc)
#update counter
here <- here + 1
#print update
if(here %% 100 == 0){
print(round(here/nrow(df), 2))
}
}
}
}
#group by iteration & method
df2 <- as.data.frame(df) %>% melt(id.vars = 1:3) %>%
group_by(network_size, t, variable) %>%
summarize(MC_Rate = mean(value, na.rm = TRUE),
se_rate = sd(value, na.rm = TRUE)) %>%
mutate(Type = rep(c('Multiplex', 'Individual'), c(5, 4)))
head(df2)
colnames(df)[3] <- "Method"
head(df2)
ggplot(df2,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
colnames(df2)[3] <- "Method"
ggplot(df2,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
ggplot(df2,
aes(t, MC_Rate, col = Method, linetype = Type)) +
geom_point(size = 2, alpha = .3)+
geom_line()+
#geom_errorbar(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .5,width = .05)+
#geom_ribbon(aes(ymin = MC_Rate - se_rate, ymax =  MC_Rate + se_rate),alpha = .1, linetype = 0)+
theme_bw()+
#scale_y_log10()+
labs(x = "t",
y = expression(paste('log'[10], '(Misclassification Rate)')))
